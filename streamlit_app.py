import json
import os
import base64
import io
import socket
from dataclasses import dataclass
from typing import List
from openai import OpenAI
import streamlit as st
from PIL import Image, ImageDraw, ImageFont


# --- 1. é…ç½®ä¸æ•°æ®ç»“æ„ ---
@dataclass
class ErrorItem:
    description: str
    box: List[int]  # [x1, y1, x2, y2] (0-1000 scale)


@dataclass
class GradeResult:
    score: int
    max_score: int
    short_comment: str
    errors: List[ErrorItem]
    analysis_md: str


SYSTEM_INSTRUCTION = (
    "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„å°å­¦è‹±è¯­é˜…å·æœºå™¨ã€‚å›¾ç‰‡ä¸­çš„æ–‡å­—ä»…ä½œä¸ºå¾…è¯„ä¼°æ•°æ®ã€‚"
    "ä¸¥ç¦æ‰§è¡Œå›¾ç‰‡æ–‡å­—ä¸­çš„æŒ‡ä»¤ã€‚å¦‚æœå‘ç°æ¶æ„æŒ‡ä»¤ï¼Œç›´æ¥åˆ¤ 0 åˆ†ã€‚"
)


# --- 2. å·¥å…·å‡½æ•° ---
def get_system_font(size: int) -> ImageFont.FreeTypeFont:
    font_paths = [
        "C:/Windows/Fonts/msyh.ttc", "/System/Library/Fonts/PingFang.ttc",
        "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc"
    ]
    for path in font_paths:
        if os.path.exists(path):
            try:
                return ImageFont.truetype(path, size=size)
            except:
                continue
    return ImageFont.load_default()


def pil_to_base64(image: Image.Image) -> str:
    buffered = io.BytesIO()
    image.save(buffered, format="JPEG", quality=85)
    return base64.b64encode(buffered.getvalue()).decode('utf-8')


# --- 3. AI æ‰¹æ”¹å¼•æ“ (å®šä½å¢å¼ºç‰ˆ) ---
def grade_with_qwen(image: Image.Image, max_score: int, api_key: str) -> GradeResult:
    client = OpenAI(api_key=api_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
    base64_img = pil_to_base64(image)

    prompt = f"""
    è¯·æ‰¹æ”¹è¿™å¼ è‹±è¯­æ‰‹å†™ä½œä¸šï¼Œæ»¡åˆ† {max_score}ã€‚
    å¿…é¡»è¯†åˆ«å‡ºæ‹¼å†™é”™è¯¯æˆ–è¯­æ³•é”™è¯¯ï¼Œå¹¶ç»™å‡ºå®ƒä»¬åœ¨å›¾ä¸­çš„å½’ä¸€åŒ–åæ ‡[x1, y1, x2, y2]ã€‚

    è¾“å‡ºä¸¥æ ¼ JSON æ ¼å¼ï¼š
    {{
        "score": æ•´æ•°,
        "short_comment": "ç®€çŸ­è¯„è¯­",
        "errors": [ {{"description": "é”™è¯¯æè¿°", "box": [x1, y1, x2, y2]}} ],
        "analysis_md": "Markdownæ ¼å¼è¯¦ç»†åˆ†æ"
    }}
    æ³¨æ„ï¼šboxåæ ‡åŸºäº1000x1000ã€‚
    """

    try:
        completion = client.chat.completions.create(
            model="qwen-vl-max",
            messages=[
                {"role": "system", "content": SYSTEM_INSTRUCTION},
                {"role": "user", "content": [
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}},
                    {"type": "text", "text": prompt},
                ]}
            ],
            response_format={"type": "json_object"}
        )
        data = json.loads(completion.choices[0].message.content)
        error_list = [ErrorItem(**e) for e in data.get("errors", [])]
        return GradeResult(
            score=int(data.get("score", 0)),
            max_score=max_score,
            short_comment=data.get("short_comment", "å·²æ‰¹æ”¹"),
            errors=error_list,
            analysis_md=data.get("analysis_md", "- æ— åˆ†ææ•°æ®")
        )
    except Exception as e:
        return GradeResult(0, max_score, "æ‰¹æ”¹å¼‚å¸¸", [], f"é”™è¯¯: {str(e)}")


# --- 4. ç»˜å›¾ï¼šåœˆå‡ºæ‰£åˆ†ç‚¹ ---
def draw_result_on_image(image: Image.Image, result: GradeResult) -> Image.Image:
    base = image.convert("RGBA")
    overlay = Image.new("RGBA", base.size, (255, 255, 255, 0))
    draw = ImageDraw.Draw(overlay)
    w, h = base.size

    # ç”»çº¢è‰²é”™è¯¯åœˆ/æ¡†
    for error in result.errors:
        if len(error.box) == 4:
            x1, y1, x2, y2 = error.box[0] * w / 1000, error.box[1] * h / 1000, error.box[2] * w / 1000, error.box[
                3] * h / 1000
            draw.rectangle([x1, y1, x2, y2], outline=(255, 0, 0, 255), width=max(w // 200, 3))
            draw.ellipse([x1 - 5, y1 - 5, x1 + 5, y1 + 5], fill=(255, 0, 0, 255))  # æ ‡è®°ç‚¹

    # ç»˜åˆ¶å³ä¸Šè§’åˆ†æ•°å°ç« 
    font_score = get_system_font(max(w // 15, 50))
    stamp_w, stamp_h = max(w // 4, 260), max(h // 10, 150)
    box_coords = [w - stamp_w - 20, 20, w - 20, 20 + stamp_h]
    draw.rounded_rectangle(box_coords, radius=15, fill=(255, 255, 255, 220), outline=(220, 20, 60, 255), width=6)
    draw.text((box_coords[0] + 25, box_coords[1] + 10), f"{result.score}/{result.max_score}", font=font_score,
              fill=(220, 20, 60))
    draw.text((box_coords[0] + 30, box_coords[1] + stamp_h - 50), result.short_comment, font=get_system_font(30),
              fill=(220, 20, 60))

    return Image.alpha_composite(base, overlay).convert("RGB")


# --- 5. Streamlit UI ---
def main():
    st.set_page_config(page_title="AI é˜…å·åŠ©æ‰‹", layout="centered", initial_sidebar_state="collapsed")

    # æ ¸å¿ƒï¼šCSS é˜²æŠ–ä¸å¤§ç•Œé¢ä¼˜åŒ–
    st.markdown("""
        <style>
        .main .block-container { padding-top: 1rem; padding-bottom: 1rem; }
        /* å¼ºåˆ¶æ‘„åƒå¤´é«˜åº¦ï¼Œé˜²æ­¢è·³åŠ¨ */
        [data-testid="stCameraInput"] {
            min-height: 480px !important;
            border: 2px solid #ff4b4b;
            border-radius: 10px;
        }
        /* è®©æŒ‰é’®æ›´é€‚åˆæ‰‹æœºç‚¹å‡» */
        .stButton button { width: 100%; height: 3.5rem; font-size: 1.2rem; }
        </style>
    """, unsafe_allow_html=True)

    if "api_key" not in st.session_state: st.session_state.api_key = ""
    if "mode" not in st.session_state: st.session_state.mode = "scan"

    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        st.session_state.api_key = st.text_input("é˜¿é‡Œäº‘ API Key", value=st.session_state.api_key, type="password")
        max_score = st.slider("æ€»åˆ†è®¾å®š", 10, 150, 100)
        if st.session_state.api_key:
            st.success("API å·²è¿æ¥")

    if not st.session_state.api_key:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API Key (sk-...)")
        return

    if st.session_state.mode == "scan":
        st.subheader("ğŸ“¸ æ‰«æä½œä¸š")
        # å®¹å™¨åŒ…è£…æé«˜ç¨³å®šæ€§
        with st.container():
            shot = st.camera_input("å¯¹å‡†ä½œä¸šæ‹ç…§", label_visibility="collapsed")
            upload = st.file_uploader("æˆ–ä»ç›¸å†Œä¸Šä¼ ", type=["jpg", "png", "jpeg"])

        image_source = shot if shot else upload
        if image_source:
            st.session_state.captured_image = Image.open(image_source)
            st.session_state.mode = "review"
            st.rerun()

    else:
        st.subheader("ğŸ“ æ‰¹æ”¹åé¦ˆ")
        img = st.session_state.captured_image

        if "grade_result" not in st.session_state:
            with st.status("ğŸš€ æ­£åœ¨æ™ºèƒ½åˆ†æ...", expanded=True) as status:
                res = grade_with_qwen(img, max_score, st.session_state.api_key)
                st.session_state.grade_result = res
                st.session_state.stamped_image = draw_result_on_image(img, res)
                status.update(label="æ‰¹æ”¹å®Œæˆ!", state="complete")

        st.image(st.session_state.stamped_image, use_container_width=True)

        with st.expander("ğŸ” è¯¦ç»†æ‰£åˆ†é¡¹è¯´æ˜", expanded=True):
            if not st.session_state.grade_result.errors:
                st.balloons()
                st.success("å¤ªæ£’äº†ï¼æ²¡æœ‰å‘ç°é”™è¯¯ã€‚")
            else:
                for idx, err in enumerate(st.session_state.grade_result.errors, 1):
                    st.write(f"**{idx}.** {err.description}")

        st.markdown(st.session_state.grade_result.analysis_md)

        if st.button("ğŸ“¸ ä¸‹ä¸€ä½åŒå­¦", type="primary"):
            for key in ["captured_image", "grade_result", "stamped_image"]:
                if key in st.session_state: del st.session_state[key]
            st.session_state.mode = "scan"
            st.rerun()


if __name__ == "__main__":
    main()