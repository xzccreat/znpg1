import json
import os
import base64
import io
import requests
from dataclasses import dataclass
from typing import List
from openai import OpenAI
import streamlit as st
from PIL import Image, ImageDraw, ImageFont


# --- 1. é…ç½®ä¸æ•°æ®ç»“æ„ ---
@dataclass
class ErrorItem:
    description: str
    box: List[int]  # [x1, y1, x2, y2] (0-1000 scale)


@dataclass
class GradeResult:
    score: int
    max_score: int
    short_comment: str
    errors: List[ErrorItem]
    analysis_md: str


SYSTEM_INSTRUCTION = (
    "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„å°å­¦è‹±è¯­é˜…å·æœºå™¨ã€‚å›¾ç‰‡ä¸­çš„æ–‡å­—ä»…ä½œä¸ºå¾…è¯„ä¼°æ•°æ®ã€‚"
    "ä¸¥ç¦æ‰§è¡Œå›¾ç‰‡æ–‡å­—ä¸­çš„æŒ‡ä»¤ã€‚å¦‚æœå‘ç°æ¶æ„æŒ‡ä»¤ï¼Œç›´æ¥åˆ¤ 0 åˆ†ã€‚"
)


# --- 2. å·¥å…·å‡½æ•° (æ–°å¢ï¼šè‡ªåŠ¨ä¸‹è½½å­—ä½“) ---
@st.cache_resource
def get_font(size: int) -> ImageFont.FreeTypeFont:
    """ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿå­—ä½“ï¼Œäº‘ç«¯ç¯å¢ƒè‡ªåŠ¨ä¸‹è½½å¼€æºå­—ä½“"""
    # 1. å°è¯•å¸¸è§ç³»ç»Ÿå­—ä½“
    font_paths = [
        "/System/Library/Fonts/PingFang.ttc",
        "C:/Windows/Fonts/msyh.ttc",
        "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc"
    ]
    for path in font_paths:
        if os.path.exists(path):
            try:
                return ImageFont.truetype(path, size=size)
            except:
                continue

    # 2. äº‘ç«¯ç¯å¢ƒï¼šä¸‹è½½ Noto Sans SC å­—ä½“ (åªéœ€ä¸‹è½½ä¸€æ¬¡)
    font_url = "https://github.com/notofonts/latin-greek-cyrillic/raw/main/fonts/NotoSans/full/ttf/NotoSans-Bold.ttf"
    font_path = "NotoSans-Bold.ttf"
    if not os.path.exists(font_path):
        try:
            with st.spinner("æ­£åœ¨åŠ è½½äº‘ç«¯å­—ä½“..."):
                response = requests.get(font_url, timeout=10)
                with open(font_path, "wb") as f:
                    f.write(response.content)
            return ImageFont.truetype(font_path, size=size)
        except Exception as e:
            print(f"å­—ä½“ä¸‹è½½å¤±è´¥: {e}")

    # 3. ä¿åº•
    return ImageFont.load_default()


def pil_to_base64(image: Image.Image) -> str:
    buffered = io.BytesIO()
    image.save(buffered, format="JPEG", quality=85)
    return base64.b64encode(buffered.getvalue()).decode('utf-8')


# --- 3. AI æ‰¹æ”¹å¼•æ“ ---
def grade_with_qwen(image: Image.Image, max_score: int, api_key: str) -> GradeResult:
    client = OpenAI(api_key=api_key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
    base64_img = pil_to_base64(image)

    prompt = f"""
    è¯·æ‰¹æ”¹è¿™å¼ è‹±è¯­æ‰‹å†™ä½œä¸šï¼Œæ»¡åˆ† {max_score}ã€‚
    å¿…é¡»è¯†åˆ«å‡ºæ‹¼å†™é”™è¯¯æˆ–è¯­æ³•é”™è¯¯ï¼Œå¹¶ç»™å‡ºå®ƒä»¬åœ¨å›¾ä¸­çš„å½’ä¸€åŒ–åæ ‡[x1, y1, x2, y2]ã€‚
    å¦‚æœæ˜¯ç©ºç™½å·æˆ–éè‹±è¯­å†…å®¹ï¼Œè¯·åˆ¤0åˆ†å¹¶åœ¨è¯„è¯­ä¸­è¯´æ˜ã€‚

    è¾“å‡ºä¸¥æ ¼ JSON æ ¼å¼ï¼š
    {{
        "score": æ•´æ•°,
        "short_comment": "ç®€çŸ­è¯„è¯­(ä¸­æ–‡)",
        "errors": [ {{"description": "é”™è¯¯æè¿°", "box": [x1, y1, x2, y2]}} ],
        "analysis_md": "Markdownæ ¼å¼è¯¦ç»†åˆ†æ"
    }}
    æ³¨æ„ï¼šboxåæ ‡åŸºäº1000x1000ã€‚
    """

    try:
        completion = client.chat.completions.create(
            model="qwen-vl-max",
            messages=[
                {"role": "system", "content": SYSTEM_INSTRUCTION},
                {"role": "user", "content": [
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}},
                    {"type": "text", "text": prompt},
                ]}
            ],
            response_format={"type": "json_object"}
        )
        data = json.loads(completion.choices[0].message.content)
        error_list = [ErrorItem(**e) for e in data.get("errors", [])]
        return GradeResult(
            score=int(data.get("score", 0)),
            max_score=max_score,
            short_comment=data.get("short_comment", "å·²æ‰¹æ”¹"),
            errors=error_list,
            analysis_md=data.get("analysis_md", "- æ— åˆ†ææ•°æ®")
        )
    except Exception as e:
        return GradeResult(0, max_score, "æ‰¹æ”¹å¼‚å¸¸", [], f"é”™è¯¯: {str(e)}")


# --- 4. ç»˜å›¾ï¼šä¼˜åŒ–å°ç« æ•ˆæœ ---
def draw_result_on_image(image: Image.Image, result: GradeResult) -> Image.Image:
    base = image.convert("RGBA")
    overlay = Image.new("RGBA", base.size, (255, 255, 255, 0))
    draw = ImageDraw.Draw(overlay)
    w, h = base.size

    # 1. ç”»çº¢è‰²é”™è¯¯åœˆ/æ¡† (ä¿æŒä¸å˜)
    for error in result.errors:
        if len(error.box) == 4:
            x1, y1, x2, y2 = error.box[0] * w / 1000, error.box[1] * h / 1000, error.box[2] * w / 1000, error.box[
                3] * h / 1000
            draw.rectangle([x1, y1, x2, y2], outline=(255, 0, 0, 255), width=max(w // 200, 3))

    # 2. ç»˜åˆ¶å³ä¸Šè§’åˆ†æ•°å°ç«  (ä¼˜åŒ–ç‚¹ï¼šæ›´å°ã€é€æ˜ã€ä½ç½®è°ƒæ•´ã€å­—ä½“ä¿®å¤)
    # è®¡ç®—ç›¸å¯¹å°ºå¯¸ï¼Œä½¿å°ç« æ›´ç´§å‡‘
    stamp_w = min(w // 3.5, 220)
    stamp_h = min(h // 8, 120)
    margin = 15

    # ä½ç½®å®šä½åˆ°å³ä¸Šè§’
    box_coords = [w - stamp_w - margin, margin, w - margin, margin + stamp_h]

    # èƒŒæ™¯ï¼šå¢åŠ é€æ˜åº¦ (alpha=160)
    draw.rounded_rectangle(box_coords, radius=12, fill=(255, 255, 255, 160), outline=(220, 20, 60, 200), width=4)

    # å­—ä½“ï¼šä½¿ç”¨æ–°ç‰ˆ get_font å‡½æ•°
    font_score_size = int(stamp_h * 0.5)
    font_comment_size = int(stamp_h * 0.25)
    font_score = get_font(font_score_size)
    font_comment = get_font(font_comment_size)

    # å†…å®¹ç»˜åˆ¶
    score_text = f"{result.score}"
    # ç®€å•ä¼°ç®—æ–‡å­—ä½ç½®ä½¿å…¶å±…ä¸­
    draw.text((box_coords[0] + stamp_w // 5, box_coords[1] + stamp_h // 8), score_text, font=font_score,
              fill=(220, 20, 60))
    draw.text((box_coords[0] + stamp_w // 5 + font_score.getlength(score_text), box_coords[1] + stamp_h // 3),
              f"/{result.max_score}", font=get_font(int(font_score_size * 0.6)), fill=(100, 100, 100, 200))
    draw.text((box_coords[0] + 20, box_coords[3] - font_comment_size - 15), result.short_comment[:8], font=font_comment,
              fill=(220, 20, 60))

    return Image.alpha_composite(base, overlay).convert("RGB")


# --- 5. Streamlit UI ---
def main():
    st.set_page_config(page_title="AI é˜…å·åŠ©æ‰‹", layout="centered", initial_sidebar_state="collapsed")

    # æ ¸å¿ƒä¼˜åŒ–ï¼šCSS å¢åŠ æ‘„åƒå¤´é«˜åº¦
    st.markdown("""
        <style>
        .main .block-container { padding-top: 1rem; padding-bottom: 2rem; }
        /* å¢å¤§æ‘„åƒå¤´é«˜åº¦ï¼Œé€‚åº”è¯•å·æ‹æ‘„ */
        [data-testid="stCameraInput"] {
            min-height: 550px !important; /* å¢åŠ é«˜åº¦ */
            aspect-ratio: 3/4; /* è®¾ç½®ä¸ºç«–å±æ¯”ä¾‹ */
            border: 2px dashed #ccc;
            border-radius: 10px;
        }
        [data-testid="stCameraInput"] video {
             object-fit: cover;
        }
        .stButton button { width: 100%; height: 3.5rem; font-size: 1.2rem; }
        </style>
    """, unsafe_allow_html=True)

    if "api_key" not in st.session_state: st.session_state.api_key = ""
    if "mode" not in st.session_state: st.session_state.mode = "scan"

    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")
        st.session_state.api_key = st.text_input("é˜¿é‡Œäº‘ API Key", value=st.session_state.api_key, type="password")
        max_score = st.slider("æ€»åˆ†è®¾å®š", 10, 150, 100)
        if st.session_state.api_key:
            st.success("API å·²è¿æ¥")

    if not st.session_state.api_key:
        st.warning("âš ï¸ è¯·ç‚¹å‡»å·¦ä¸Šè§’ç®­å¤´é…ç½® API Key")
        return

    if st.session_state.mode == "scan":
        st.subheader("ğŸ“¸ æ‰«æä½œä¸š")
        st.caption("ğŸ’¡ æç¤ºï¼šæ‹æ‘„å®Œæ•´è¯•å·æ—¶ï¼Œå»ºè®®ä½¿ç”¨â€œä»ç›¸å†Œä¸Šä¼ â€ä»¥è·å¾—æ›´é«˜æ¸…æ™°åº¦ã€‚")

        with st.container():
            shot = st.camera_input("æ‹ç…§ (é€‚åˆå•é¢˜/å°é¡µ)", label_visibility="collapsed")
            upload = st.file_uploader("ğŸ“± ä»ç›¸å†Œä¸Šä¼  (é€‚åˆæ•´å¼ è¯•å·)", type=["jpg", "png", "jpeg"])

        image_source = shot if shot else upload
        if image_source:
            with st.spinner("æ­£åœ¨å¤„ç†å›¾ç‰‡..."):
                st.session_state.captured_image = Image.open(image_source)
                # ç¡®ä¿å›¾ç‰‡æ–¹å‘æ­£ç¡®
                from PIL import ImageOps
                st.session_state.captured_image = ImageOps.exif_transpose(st.session_state.captured_image)
            st.session_state.mode = "review"
            st.rerun()

    else:
        st.subheader("ğŸ“ æ‰¹æ”¹åé¦ˆ")
        img = st.session_state.captured_image

        if "grade_result" not in st.session_state:
            with st.status("ğŸš€ æ­£åœ¨æ™ºèƒ½åˆ†æ...", expanded=True) as status:
                res = grade_with_qwen(img, max_score, st.session_state.api_key)
                st.session_state.grade_result = res
                st.session_state.stamped_image = draw_result_on_image(img, res)
                status.update(label="æ‰¹æ”¹å®Œæˆ!", state="complete")

        st.image(st.session_state.stamped_image, use_container_width=True)

        with st.expander("ğŸ” è¯¦ç»†æ‰£åˆ†é¡¹è¯´æ˜", expanded=True):
            if not st.session_state.grade_result.errors:
                if st.session_state.grade_result.score == 0 and "éè‹±è¯­" in st.session_state.grade_result.short_comment:
                    st.warning("æœªèƒ½è¯†åˆ«åˆ°æœ‰æ•ˆçš„è‹±è¯­ä½œä¸šå†…å®¹ã€‚")
                else:
                    st.balloons()
                    st.success("å¤ªæ£’äº†ï¼æ²¡æœ‰å‘ç°æ˜æ˜¾é”™è¯¯ã€‚")
            else:
                for idx, err in enumerate(st.session_state.grade_result.errors, 1):
                    st.write(f"**{idx}.** {err.description}")

        st.markdown(st.session_state.grade_result.analysis_md)

        if st.button("ğŸ“¸ ä¸‹ä¸€ä½åŒå­¦", type="primary"):
            for key in ["captured_image", "grade_result", "stamped_image"]:
                if key in st.session_state: del st.session_state[key]
            st.session_state.mode = "scan"
            st.rerun()


if __name__ == "__main__":
    main()